{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from random import sample\n",
    "import random\n",
    "import numpy as np\n",
    "from numpy import diag\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class State(numpy.ndarray):\n",
    "    symbols = {0: \"_\", 1: \"X\", 2: \"O\"}\n",
    "    \n",
    "    #3x3 array of zeros\n",
    "    def __new__(subtype): \n",
    "        arr = numpy.zeros((3,3), dtype=numpy.int8)\n",
    "        return arr.view(subtype)\n",
    "\n",
    "    def __hash__(s): \n",
    "        flat = s.ravel() #array as vector\n",
    "        code = 0\n",
    "        for i in xrange(9): code += pow(3,i) * flat[i] #xrange(9) = seq(1,9) in R, pow(3,i) = 3^i\n",
    "        return code\n",
    "\n",
    "    def won(s, player): #all possibilities of winning\n",
    "        x = s == player\n",
    "        return numpy.hstack( (x.all(0), x.all(1), diag(x).all(), diag(x[:,::-1]).all()) ).any() #hstack = cbind in R\n",
    "\n",
    "    def full(s):\n",
    "        return (s != 0).all()\n",
    "\n",
    "    def __str__(s): #fill the board with current state\n",
    "        out = [\"\"]\n",
    "        for i in xrange(3):\n",
    "            for j in xrange(3):\n",
    "                out.append( s.symbols[ s[i,j] ] ) #we defined the possible symbols at the begining of the class\n",
    "            out.append(\"\\n\")\n",
    "        return str(\" \").join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Learner:\n",
    "    #Player\n",
    "    def __init__(s, player, alpha = None, gamma = None):\n",
    "        s.valuefunc = dict()\n",
    "        s.laststate_hash = None\n",
    "        s.player = player\n",
    "        s.gamehist = []\n",
    "        s.traced = False\n",
    "        \n",
    "        # I did something here\n",
    "        if player == 1:\n",
    "            if alpha == None: \n",
    "                s.alpha = 0.2 \n",
    "            else: \n",
    "                s.alpha = alpha\n",
    "            if gamma == None: \n",
    "                s.gamma = 0.5 \n",
    "            else: s.gamma = gamma\n",
    "        else: \n",
    "            if alpha == None: \n",
    "                s.alpha = 0.4 \n",
    "            else: s.alpha = alpha\n",
    "            if gamma == None: \n",
    "                s.gamma = 0.7 \n",
    "            else: s.gamma = gamma\n",
    "       \n",
    "    def enum_actions(s, state):\n",
    "        #enumerate all possible actions from given state\n",
    "        res = list()\n",
    "        for i in xrange(3):\n",
    "            for j in xrange(3):\n",
    "                #if a given position in the given state\n",
    "                #is still empty then add it as a possible action \n",
    "                if state[i,j] == 0:\n",
    "                    res.append( (i,j) )\n",
    "        #return list of all possible actions\n",
    "        return res\n",
    "\n",
    "    def value(s, state, action): #measures the gain after a particular step\n",
    "        \"Assumption: Game has not been won by other player\"\n",
    "        #modify the state: put to the given place(action) the given symbol(player)\n",
    "        state[action] = s.player\n",
    "        #hash value is an id used to compare disctionary keys quickly, gives another value to floats (keeps order)\n",
    "        #id of new state\n",
    "        hashval = hash(state)\n",
    "        #access value of the new state\n",
    "        val = s.valuefunc.get( hashval )\n",
    "\n",
    "        #if new state has no value yet\n",
    "        if val == None:\n",
    "            #if new state is winning assign value 1\n",
    "            if state.won(s.player): val = 1.0\n",
    "            #if new state is final but player did not win assign value 0\n",
    "            elif state.full(): val = 0.0\n",
    "            #else, game continues\n",
    "            else: val = 0.1\n",
    "            #assign value to the new state\n",
    "            s.valuefunc[hashval] = val\n",
    "        #reset state to the old value (I guess we call \"value\" only for possible action, \n",
    "        #meaning we step only to empty positions)    \n",
    "        state[action] = 0\n",
    "        #return value of the new state\n",
    "        return val\n",
    "    \n",
    "    def next_action(s, state): #decide action after maximizing gain\n",
    "        valuemap = list()\n",
    "        #enumerate over all possible actions\n",
    "        for action in s.enum_actions(state):\n",
    "            #check value of the new state if you make a possible action\n",
    "            val = s.value(state, action)\n",
    "            #add it to value map associated with the given action\n",
    "            valuemap.append( (val, action) )\n",
    "\n",
    "        # I did something here\n",
    "\n",
    "        # Random Choice before sorting \n",
    "        rc = sample(valuemap,1)[0]\n",
    "\n",
    "        # I did something here\n",
    "\n",
    "        #Find the actions with the highest value\n",
    "        valuemap.sort(key=lambda x:x[0], reverse=True)\n",
    "        maxval = valuemap[0][0]\n",
    "        valuemap = filter(lambda x: x[0] >= maxval, valuemap)\n",
    "        #randomize over the max value actions and return one of them \n",
    "        opt = sample(valuemap,1)[0]\n",
    "\n",
    "        split = np.random.choice(2, 1, p=[s.gamma, 1-s.gamma]).tolist()[0]\n",
    "        if split == 1:\n",
    "            return rc\n",
    "        else:\n",
    "            return opt\n",
    "\n",
    "    def next(s, state):\n",
    "        #If the other player won assign value -1\n",
    "        if state.won(3-s.player):\n",
    "            val = -1\n",
    "        #If the game ended assign value 0.1\n",
    "        elif state.full():\n",
    "            val = -0.1\n",
    "        else:\n",
    "            #Otherwise find the best action with the associated value\n",
    "            (val, action) = s.next_action(state)\n",
    "            #Redefine state according to this action (put the given \n",
    "            #player`s sign to the optimal action)\n",
    "            state[action] = s.player\n",
    "            \n",
    "        if state.won(1) or state.won(2) or state.full():\n",
    "            #If game is finish change traced value to true\n",
    "            s.traced = True\n",
    "            \n",
    "        #learning step\n",
    "        #If there was a previous state\n",
    "        if s.laststate_hash != None:\n",
    "            #update the value of the previous state (meaning the state you were in the previous step) \n",
    "            #based on the original values of the previous states, valuefunc, and the value of the new state, val\n",
    "            s.valuefunc[s.laststate_hash] = (1.0-s.alpha) * s.valuefunc[s.laststate_hash] + s.alpha * val\n",
    "        #update laststate value\n",
    "        s.laststate_hash = hash(state)\n",
    "        #append previous state to the game history\n",
    "        s.gamehist.append(s.laststate_hash)\n",
    "        \n",
    "    def reset(s):\n",
    "        #reset the class except valuefunction\n",
    "        #basically start new game but keep values you already updated\n",
    "        s.laststate_hash = None\n",
    "        s.gamehist = []\n",
    "        s.traced = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Game:\n",
    "    #description of the game = the variable \n",
    "    #what objects it should have inside\n",
    "\n",
    "    # FELIX ALSO DESTROYED SOMETHING HERE\n",
    "    def __init__(s, learner = None , other = None ):\n",
    "        if learner == None: \n",
    "            s.learner = Learner(player=2) #define if we want a second player \n",
    "        else:\n",
    "            s.learner = learner\n",
    "        if other == None:\n",
    "            s.other = Learner(player=1)\n",
    "        else:\n",
    "            s.other = other\n",
    "        s.reset() #define that reset is part of the game \n",
    "        s.sp = Selfplay(learner = s.learner,other = s.other) #if we want self learning\n",
    "    \n",
    "    #define the reset function    \n",
    "    def reset(s):\n",
    "        s.state = State() \n",
    "        s.learner.reset() \n",
    "        print sample([\"WELCOME TO YOUR NIGHTMARE\", \"DID YOU KNOW I BEAT THE BEST NORTH KOREAN PLAYER?\", \"YOU CANNOT BEAT THE TICTACTOE MASTER\"], 1)\n",
    "        print s.state\n",
    "\n",
    "    def __call__(s, pi,pj): \n",
    "        j = pi -1 #take the first coordinate of the previous state\n",
    "        i = pj - 1 #take the second coordinate of the previous state\n",
    "        if s.state[j,i] == 0:\n",
    "            s.state[j,i] = 1 #mark cell as played by human\n",
    "            s.learner.next(s.state)\n",
    "        else:\n",
    "            print sample([\"TRY ANOTHER MOVE\", \"CMON MAN...\", \"ARE YOU OKAY?\"], 1)\n",
    "        print s.state #,hash(s.state)\n",
    "\n",
    "        if s.state.full() or s.state.won(1) or s.state.won(2):\n",
    "            if s.state.won(1):\n",
    "                print sample([\"YOU WERE LUCKY\", \"NEXT TIME... IT'S ME!\", \"HUMAN, YOU WIN...\"], 1)\n",
    "            elif s.state.won(2):\n",
    "                print sample([\"I WIN HAHAHA!\", \"YO IS THIS GAME TOO HARD FOR YOU?\", \"ROBOTS WILL MAKE YOU UNEMPLOYED\"], 1)\n",
    "            else:\n",
    "                print \"DRAW\"\n",
    "            s.reset() #reset the game \n",
    "\n",
    "    def selfplay(s, n=1000):\n",
    "        #selfplay for specific number of rounds\n",
    "        for i in xrange(n):\n",
    "            s.sp.play() \n",
    "        s.reset() #in the end reset again\n",
    "    #use the package cPicle to save the dictionary \n",
    "    def save(s):\n",
    "        cPickle.dump(s.learner, open(\"learn.dat\", \"w\")) #open is for the appointing the name file \n",
    "        # w = write, we can even add wb so that it is portable between Windows and Unix \n",
    "    #use the package cPicle to load the dictionary \n",
    "    def load(s):\n",
    "        s.learner = cPickle.load( open(\"learn.dat\") ) #read the dictionary\n",
    "        s.sp = Selfplay(s.learner) #selfplay using that dictionary \n",
    "        s.reset() # reset at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Selfplay:\n",
    "    \n",
    "    # FELIX WAS HERE AGAIN\n",
    "    \n",
    "    def __init__(s, learner = None, other = None ):\n",
    "        # No learner argument --> Create Learner Class for Player 2 \n",
    "        if learner == None:\n",
    "            s.learner = Learner(player=2)\n",
    "        # If learner class is passed assign it to learner object   \n",
    "        else:\n",
    "            s.learner = learner\n",
    "        \n",
    "        if other == None:\n",
    "        # Create oponent player \n",
    "            s.other = Learner(player=1)\n",
    "        else: \n",
    "            s.other = other\n",
    "        # Set counter to zero\n",
    "        s.i = 0\n",
    "\n",
    "        # MY STUFF\n",
    "        s.wining = []\n",
    "        s.valuesave = dict()\n",
    "\n",
    "\n",
    "    def reset(s):\n",
    "        # Create state class\n",
    "        s.state = State()\n",
    "        # Reset both players \n",
    "        s.learner.reset()\n",
    "        s.other.reset()\n",
    "\n",
    "    # Play the mo#!%*** game\n",
    "    def play(s):\n",
    "        # Initliaze states and players\n",
    "        s.reset()\n",
    "\n",
    "        while True:\n",
    "            # Update states of both players \n",
    "            s.other.next(s.state)    \n",
    "            s.learner.next(s.state)\n",
    "\n",
    "            # Check if board is full or if player 1 or 2 won \n",
    "            if s.state.full() or s.state.won(1) or s.state.won(2):\n",
    "                # FALSE: Update counter\n",
    "                s.i += 1\n",
    "                # In every 100th iteration print the current state\n",
    "                #if s.i % 10 == 0:\n",
    "                    #print s.state #hash(s.state)\n",
    "                # If game is not finish do the the optimised next step\n",
    "                if not s.other.traced:\n",
    "                    s.other.next(s.state)\n",
    "\n",
    "                # MY STUFF\n",
    "                # AND NOW WE ARE LAUGHING\n",
    "                if s.state.won(1): s.wining.append(1)\n",
    "                elif s.state.won(2): s.wining.append(2)\n",
    "                else: s.wining.append(0)\n",
    "                for i in [2,6,18,162]:\n",
    "                    s.other.valuefunc\n",
    "                    if s.valuesave.get(i) == None: s.valuesave[i] = [s.other.valuefunc[i]]\n",
    "                    else: s.valuesave[i].append(s.other.valuefunc[i])\n",
    "                \n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** CHALLENGE THE BEST TIC TAC TOE PLAYER ***\n",
      "PLAY USING g(i,j), WHERE i IS A ROW AND j A COLUMN\n",
      "WRITE g.selfplay(1000) TO MAKE ME 1000 TIMES STRONGER\n",
      "['DID YOU KNOW I BEAT THE BEST NORTH KOREAN PLAYER?']\n",
      " _ _ _ \n",
      " _ _ _ \n",
      " _ _ _ \n",
      "\n",
      "['WELCOME TO YOUR NIGHTMARE']\n",
      " _ _ _ \n",
      " _ _ _ \n",
      " _ _ _ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print \"*** CHALLENGE THE BEST TIC TAC TOE PLAYER ***\"\n",
    "    print \"PLAY USING g(i,j), WHERE i IS A ROW AND j A COLUMN\"\n",
    "    print \"WRITE g.selfplay(1000) TO MAKE ME 1000 TIMES STRONGER\"\n",
    "    g = Game()\n",
    "\n",
    "# def __init__(s, player, alpha = None, gamma = None):\n",
    "p1 = Learner(player = 1, alpha = 0.2,gamma = 0)\n",
    "p2 = Learner(player = 2, alpha = 0.2,gamma = 0)\n",
    "g2 = Game(learner = p2,other=p1)\n",
    "\n",
    "p1 = Learner(player = 1, alpha = 0.5,gamma = 0.3)\n",
    "p2 = Learner(player = 2, alpha = 0.5,gamma = 0.3)\n",
    "g2 = Game(learner = p2,other=p1)\n",
    "\n",
    "p1 = Learner(player = 1, alpha = 0.5,gamma = 0.3)\n",
    "p2 = Learner(player = 2, alpha = 0.5,gamma = 0.3)\n",
    "g2 = Game(learner = p2,other=p1)\n",
    "\n",
    "p1 = Learner(player = 1, alpha = 0.5,gamma = 0.3)\n",
    "p2 = Learner(player = 2, alpha = 0.5,gamma = 0.3)\n",
    "g2 = Game(learner = p2,other=p1)\n",
    "\n",
    "p1 = Learner(player = 1, alpha = 0.5,gamma = 0.3)\n",
    "p2 = Learner(player = 2, alpha = 0.5,gamma = 0.3)\n",
    "g2 = Game(learner = p2,other=p1)\n",
    "\n",
    "p1 = Learner(player = 1, alpha = 0.5,gamma = 0.3)\n",
    "p2 = Learner(player = 2, alpha = 0.5,gamma = 0.3)\n",
    "g2 = Game(learner = p2,other=p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      " _ _ _ \n",
      " _ X _ \n",
      " _ _ _ \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check hash value of given states\n",
    "state = State()\n",
    "state[1,1] = 1\n",
    "#state[1,2] = 2\n",
    "print(hash(state))\n",
    "print(str(state))\n",
    "\n",
    "8/10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['YOU CANNOT BEAT THE TICTACTOE MASTER']\n",
      " _ _ _ \n",
      " _ _ _ \n",
      " _ _ _ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "g2.selfplay() 7 19 163 13123 5 165 13125 13203 567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 18, 6, 162]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g2.sp.valuesave[2])\n",
    "g2.sp.valuesave[2]\n",
    "g2.sp.valuesave.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# red dashes, blue squares and green triangles\n",
    "plt.plot(range(1,len(g2.sp.valuesave[2]) + 1), g2.sp.valuesave[2], 'r-', \n",
    "         range(1,len(g2.sp.valuesave[18]) + 1), g2.sp.valuesave[18], 'b-', \n",
    "         range(1,len(g2.sp.valuesave[6]) + 1), g2.sp.valuesave[6], 'g-',\n",
    "         range(1,len(g2.sp.valuesave[162]) + 1), g2.sp.valuesave[162], 'y-')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
